{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "- Random Color Jitter\n",
    "- Random Horizontal Flip\n",
    "- Random Rotation\n",
    "- Random Resize and Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "os.chdir(\"../models\")\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from common_utils import set_seed, EarlyStopper, train, get_mean_rgb, test_model\n",
    "from datetime import datetime\n",
    "from model import DepthPointWiseCNN\n",
    "from sklearn.metrics import top_k_accuracy_score, f1_score\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms.v2 import MixUp, CutMix, RandomChoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up variables, seed and pytorch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['AugmentModel', 42, 0.05, 0.001, 0.0001], 'cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We might want to run the notebook with different parameters using a script\n",
    "# Use environment varables to set the parameters if thats the case\n",
    "defaults = {\n",
    "    \"model_name\": \"AugmentModel\",\n",
    "    \"model_seed\": 42,\n",
    "    \"batchnorm_moment\": 0.05,\n",
    "    \"max_lr\": 0.001,\n",
    "    \"min_lr\": 0.0001\n",
    "}\n",
    "for k, v in defaults.items():\n",
    "    globals()[k] = os.environ.get(k, defaults[k])\n",
    "    # Use default value type to infer the variable type\n",
    "    if isinstance(v, int):\n",
    "        globals()[k] = int(globals()[k])\n",
    "    elif isinstance(v, float):\n",
    "        globals()[k] = float(globals()[k])\n",
    "\n",
    "# set seed\n",
    "set_seed(model_seed)\n",
    "\n",
    "device_type = None\n",
    "device = None\n",
    "# determine device type\n",
    "if torch.cuda.is_available(): # nvidia gpu\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_type = \"cuda\"\n",
    "elif torch.backends.mps.is_available(): # apple gpu\n",
    "    device = torch.device(\"mps\")\n",
    "    device_type = \"mps\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_type = \"mps\"\n",
    "\n",
    "[globals()[k] for k in defaults.keys()], device_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DepthPointWiseCNN(batchnorm_moment=batchnorm_moment,\n",
    "                          dropout_rate=0.05).to(device_type) # initialise model\n",
    "data_dir_path = \"../data\"\n",
    "\n",
    "# Make directory to save baseline model\n",
    "# Don't overwrite exisiting models and model outputs\n",
    "model_path = f\"./saved_models/{model_name}/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "else:\n",
    "    raise Exception('''\n",
    "        Directory already exists. Either choose a different 'model_name' or\n",
    "        delete the exisiting directory.\n",
    "    ''')\n",
    "\n",
    "# Construct the full path\n",
    "device_path = os.path.join(model_path, device_type)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(device_path):\n",
    "    os.mkdir(device_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_collate_fn(batch):\n",
    "    mixup = MixUp(num_classes=102, alpha=mixup_alpha)\n",
    "    cutmix = CutMix(num_classes=102, alpha=cutmix_alpha)\n",
    "\n",
    "    return RandomChoice([mixup, cutmix])(*default_collate(batch))\n",
    "\n",
    "data_path = \"../data\"\n",
    "\n",
    "batch_size = 128\n",
    "mixup_alpha = 0.2\n",
    "cutmix_alpha = 1.0\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ColorJitter(brightness=0.2, saturation=0.2),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    # Random rotation triples the time\n",
    "    # transforms.RandomRotation((-30, 30)),\n",
    "    transforms.RandomResizedCrop((100, 100), scale=(0.8, 1.0), antialias=True),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((100, 100), antialias=True),\n",
    "])\n",
    "\n",
    "# load data\n",
    "# NOTE: Due to a bug with the Flowers102 dataset, the train and test splits are swapped\n",
    "train_dataset = datasets.Flowers102(root=data_path,\n",
    "                                    split='test',\n",
    "                                    download=True,\n",
    "                                    transform=train_transform\n",
    "                                   ) \n",
    "val_dataset = datasets.Flowers102(root=data_path,\n",
    "                                  split='val',\n",
    "                                  download=True,\n",
    "                                  transform=transform\n",
    "                                 ) \n",
    "test_dataset = datasets.Flowers102(root=data_path,\n",
    "                                   split='train',\n",
    "                                   download=True,\n",
    "                                   transform=transform\n",
    "                                  )\n",
    "\n",
    "# initialise dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=mixup_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = min_lr # learning rate\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr) # initialise optimiser\n",
    "loss = torch.nn.CrossEntropyLoss() # initialise loss function\n",
    "epochs = 30\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser,\n",
    "                                                max_lr=max_lr,\n",
    "                                                steps_per_epoch=len(train_dataloader),\n",
    "                                                epochs=epochs)\n",
    "\n",
    "patience = 10\n",
    "early_stopper = EarlyStopper(patience=patience) # initialise early stopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 49/49 [01:01<00:00,  1.26s/it, Training loss=4.3893, Learning rate=0.00007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 took 65.76s | Train loss: 4.3893 | Val loss: 4.6629 | Val accuracy: 0.98% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, Training loss=3.9543, Learning rate=0.00015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 took 61.83s | Train loss: 3.9543 | Val loss: 4.1389 | Val accuracy: 8.14% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 49/49 [00:58<00:00,  1.20s/it, Training loss=3.8608, Learning rate=0.00028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 took 62.93s | Train loss: 3.8608 | Val loss: 3.6101 | Val accuracy: 14.22% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 49/49 [00:56<00:00,  1.16s/it, Training loss=3.5217, Learning rate=0.00044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 took 61.16s | Train loss: 3.5217 | Val loss: 3.2534 | Val accuracy: 21.57% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, Training loss=3.1694, Learning rate=0.00061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 took 62.53s | Train loss: 3.1694 | Val loss: 3.0334 | Val accuracy: 23.73% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 49/49 [00:57<00:00,  1.18s/it, Training loss=3.0400, Learning rate=0.00076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 took 62.24s | Train loss: 3.0400 | Val loss: 2.7862 | Val accuracy: 31.86% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, Training loss=3.0080, Learning rate=0.00089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 took 61.49s | Train loss: 3.0080 | Val loss: 2.4019 | Val accuracy: 35.00% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, Training loss=2.6229, Learning rate=0.00097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 took 63.02s | Train loss: 2.6229 | Val loss: 2.0610 | Val accuracy: 46.96% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 49/49 [00:59<00:00,  1.21s/it, Training loss=2.4706, Learning rate=0.00100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 took 63.77s | Train loss: 2.4706 | Val loss: 2.1169 | Val accuracy: 43.63% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 49/49 [00:56<00:00,  1.16s/it, Training loss=2.4694, Learning rate=0.00099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 took 60.75s | Train loss: 2.4694 | Val loss: 1.8740 | Val accuracy: 48.82% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 49/49 [00:56<00:00,  1.15s/it, Training loss=2.4075, Learning rate=0.00098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 took 60.56s | Train loss: 2.4075 | Val loss: 1.6884 | Val accuracy: 57.94% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, Training loss=2.3535, Learning rate=0.00095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 took 61.80s | Train loss: 2.3535 | Val loss: 1.7360 | Val accuracy: 52.35% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 49/49 [00:57<00:00,  1.17s/it, Training loss=2.0897, Learning rate=0.00091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 took 61.75s | Train loss: 2.0897 | Val loss: 2.0038 | Val accuracy: 51.08% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 49/49 [00:57<00:00,  1.18s/it, Training loss=2.1514, Learning rate=0.00087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 took 61.91s | Train loss: 2.1514 | Val loss: 1.6110 | Val accuracy: 59.31% | EarlyStopper count: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 49/49 [00:54<00:00,  1.10s/it, Training loss=2.0111, Learning rate=0.00081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 took 58.11s | Train loss: 2.0111 | Val loss: 1.4235 | Val accuracy: 62.55% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, Training loss=2.0150, Learning rate=0.00075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 took 62.65s | Train loss: 2.0150 | Val loss: 1.3097 | Val accuracy: 65.29% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 49/49 [00:57<00:00,  1.18s/it, Training loss=1.8209, Learning rate=0.00068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 took 62.28s | Train loss: 1.8209 | Val loss: 1.3557 | Val accuracy: 64.22% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 49/49 [00:56<00:00,  1.15s/it, Training loss=1.8355, Learning rate=0.00061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 took 60.62s | Train loss: 1.8355 | Val loss: 1.2518 | Val accuracy: 67.75% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 49/49 [00:56<00:00,  1.16s/it, Training loss=1.9323, Learning rate=0.00054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 took 60.67s | Train loss: 1.9323 | Val loss: 1.2860 | Val accuracy: 66.96% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 49/49 [00:58<00:00,  1.20s/it, Training loss=1.3940, Learning rate=0.00046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 took 62.94s | Train loss: 1.3940 | Val loss: 1.1315 | Val accuracy: 72.94% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, Training loss=1.6251, Learning rate=0.00039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 took 62.61s | Train loss: 1.6251 | Val loss: 1.0841 | Val accuracy: 73.04% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 49/49 [00:55<00:00,  1.13s/it, Training loss=1.8203, Learning rate=0.00032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 took 59.62s | Train loss: 1.8203 | Val loss: 1.0119 | Val accuracy: 75.29% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 49/49 [00:56<00:00,  1.16s/it, Training loss=1.2230, Learning rate=0.00025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 took 61.15s | Train loss: 1.2230 | Val loss: 1.0296 | Val accuracy: 75.39% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 49/49 [00:57<00:00,  1.18s/it, Training loss=1.4943, Learning rate=0.00019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 took 62.47s | Train loss: 1.4943 | Val loss: 1.0153 | Val accuracy: 75.20% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 49/49 [00:59<00:00,  1.21s/it, Training loss=1.5045, Learning rate=0.00013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 took 63.60s | Train loss: 1.5045 | Val loss: 0.9787 | Val accuracy: 76.27% | EarlyStopper count: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 49/49 [00:57<00:00,  1.18s/it, Training loss=1.4693, Learning rate=0.00009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 took 62.17s | Train loss: 1.4693 | Val loss: 0.9752 | Val accuracy: 76.08% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 49/49 [00:59<00:00,  1.21s/it, Training loss=1.7226, Learning rate=0.00005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 took 63.55s | Train loss: 1.7226 | Val loss: 0.9626 | Val accuracy: 76.37% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 49/49 [00:58<00:00,  1.19s/it, Training loss=1.6507, Learning rate=0.00002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 took 62.93s | Train loss: 1.6507 | Val loss: 0.9650 | Val accuracy: 76.67% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 49/49 [00:52<00:00,  1.07s/it, Training loss=1.5006, Learning rate=0.00001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 took 56.45s | Train loss: 1.5006 | Val loss: 0.9826 | Val accuracy: 75.78% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30:  82%|████████▏ | 40/49 [00:49<00:11,  1.25s/it, Training loss=1.3784, Learning rate=0.00000]"
     ]
    }
   ],
   "source": [
    "out = train(model, train_dataloader, val_dataloader, optimiser,\n",
    "            loss, device, epochs, early_stopper, device_path, scheduler\n",
    "           )\n",
    "train_loss_list, val_loss_list, val_acc_list, train_time_list, lr_list, early_stop = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train, test loss and test accuracy\n",
    "Note that this is only to visualize how the training was. We will create nicer plots for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_list, label=\"train loss\")\n",
    "plt.plot(val_loss_list, label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_acc_list, label=\"val accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(device_path, 'best_model.pt'))\n",
    "\n",
    "best_model = DepthPointWiseCNN().to(device_type)\n",
    "best_model.load_state_dict(checkpoint)\n",
    "\n",
    "true_labels = torch.stack([label for _, label in test_dataloader])\n",
    "pred_softmax_labels = test_model(best_model, test_dataloader, loss, device).cpu()\n",
    "pred_labels = torch.argmax(pred_softmax_labels, dim=1)\n",
    "\n",
    "top_1_accuracy = top_k_accuracy_score(true_labels, pred_softmax_labels, k=1)\n",
    "top_5_accuracy = top_k_accuracy_score(true_labels, pred_softmax_labels, k=5)\n",
    "f1 = f1_score(true_labels, pred_labels, average='micro')\n",
    "\n",
    "top_1_accuracy, top_5_accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all relevant data/parameters to be used for plots, etc\n",
    "Note that different models may have the same parameters. There's no guarantee that they can be accessible across different computers. There may also be some redundant parameters added just in case we might need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"time_trained\": datetime.now().strftime(\"%D,%H:%M:%S\"),\n",
    "    \"model_name\": model_name,\n",
    "    \"model_seed\": model_seed,\n",
    "    \"device_type\": device_type,\n",
    "    \n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_transform\": train_transform,\n",
    "    \"transform\": transform,\n",
    "    \n",
    "    \"lr\": lr,\n",
    "    \"epochs\": epochs,\n",
    "    \"patience\": patience,\n",
    "    \n",
    "    \"train_loss_list\": train_loss_list,\n",
    "    \"val_loss_list\": val_loss_list,\n",
    "    \"val_acc_list\": val_acc_list,\n",
    "    \"train_time_list\": train_time_list,\n",
    "    \"lr_list\": lr_list,\n",
    "    \"early_stop\": early_stop,   # Boolean for if early stopping happened\n",
    "\n",
    "    \"true_labels\": true_labels,\n",
    "    \"pred_softmax_labels\": pred_softmax_labels,\n",
    "    \"pred_labels\": pred_labels,\n",
    "    \"top_1_accuracy\": top_1_accuracy,\n",
    "    \"top_5_accuracy\": top_5_accuracy,\n",
    "    \"f1\": f1,\n",
    "\n",
    "    \"batchnorm_moment\": batchnorm_moment\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_path, \"data.pickle\"), \"wb\") as f: \n",
    "    pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
