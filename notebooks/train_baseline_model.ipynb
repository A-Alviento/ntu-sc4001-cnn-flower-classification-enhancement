{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook trains our baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "os.chdir(\"../models\")\n",
    "from model import CustomCNN\n",
    "from common_utils import set_seed, EarlyStopper, train, get_mean_rgb, CustomTransform\n",
    "\n",
    "# set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN() # initialise model\n",
    "\n",
    "mean_rgb = get_mean_rgb(datasets.Flowers102(root='../data', split='test', download=True, transform=transforms.ToTensor())) # get mean rgb values of dataset\n",
    "transform = CustomTransform(mean_rgb) # initialise transform\n",
    "\n",
    "# load data\n",
    "train_dataset = datasets.Flowers102(root='../data', split='test', download=True, transform=transform) \n",
    "val_dataset = datasets.Flowers102(root='../data', split='val', download=True, transform=transform) \n",
    "test_dataset = datasets.Flowers102(root='../data', split='train', download=True, transform=transform)\n",
    "# NOTE: Due to a bug with the Flowers102 dataset, the train and test splits are swapped\n",
    "\n",
    "# initialise dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # learning rate\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr) # initialise optimiser\n",
    "loss = torch.nn.CrossEntropyLoss() # initialise loss function\n",
    "\n",
    "if torch.cuda.is_available(): # nvidia gpu\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): # apple gpu\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 100 # number of epochs\n",
    "early_stopper = EarlyStopper(patience=10) # initialise early stopper\n",
    "\n",
    "\n",
    "# Make directory to save baseline model\n",
    "baseline_model_path = \"./saved_models/baseline_model\"\n",
    "if not os.path.exists(baseline_model_path):\n",
    "    os.mkdir(baseline_model_path)\n",
    "\n",
    "# Define the device-specific path\n",
    "device_type = None\n",
    "if device == torch.device(\"cuda\"):\n",
    "    device_type = \"cuda\"\n",
    "elif device == torch.device(\"mps\"):\n",
    "    device_type = \"mps\"\n",
    "else:\n",
    "    device_type = \"cpu\"\n",
    "\n",
    "# Construct the full path\n",
    "device_path = os.path.join(baseline_model_path, device_type)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(device_path):\n",
    "    os.mkdir(device_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrian/miniconda3/envs/sc4001/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Epoch 1/100: 100%|██████████| 193/193 [01:17<00:00,  2.49it/s, Training loss=4.4661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 took 83.72s | Train loss: 4.4661 | Val loss: 4.6956 | Val accuracy: 0.98% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 193/193 [01:13<00:00,  2.63it/s, Training loss=4.3915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 took 80.09s | Train loss: 4.3915 | Val loss: 4.6821 | Val accuracy: 1.96% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 193/193 [01:13<00:00,  2.64it/s, Training loss=4.0872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 took 79.55s | Train loss: 4.0872 | Val loss: 4.3190 | Val accuracy: 2.55% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 193/193 [01:13<00:00,  2.64it/s, Training loss=3.9260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 took 79.39s | Train loss: 3.9260 | Val loss: 4.2229 | Val accuracy: 2.45% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 193/193 [01:17<00:00,  2.49it/s, Training loss=3.7876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 took 83.79s | Train loss: 3.7876 | Val loss: 4.0558 | Val accuracy: 5.29% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 193/193 [01:13<00:00,  2.64it/s, Training loss=3.6581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 took 79.54s | Train loss: 3.6581 | Val loss: 3.8943 | Val accuracy: 5.88% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 193/193 [01:12<00:00,  2.66it/s, Training loss=3.5408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 took 78.83s | Train loss: 3.5408 | Val loss: 3.7368 | Val accuracy: 8.82% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 193/193 [01:13<00:00,  2.64it/s, Training loss=3.4373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 took 79.23s | Train loss: 3.4373 | Val loss: 3.6399 | Val accuracy: 9.22% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 193/193 [01:12<00:00,  2.65it/s, Training loss=3.3196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 took 79.05s | Train loss: 3.3196 | Val loss: 3.4839 | Val accuracy: 11.37% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 193/193 [01:13<00:00,  2.62it/s, Training loss=3.1896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 took 80.33s | Train loss: 3.1896 | Val loss: 3.5068 | Val accuracy: 12.84% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 193/193 [01:13<00:00,  2.64it/s, Training loss=3.0766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 took 79.49s | Train loss: 3.0766 | Val loss: 3.3398 | Val accuracy: 15.20% | EarlyStopper count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 193/193 [01:16<00:00,  2.51it/s, Training loss=2.9701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 took 83.21s | Train loss: 2.9701 | Val loss: 3.3001 | Val accuracy: 17.16% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 193/193 [01:20<00:00,  2.41it/s, Training loss=2.8453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 took 86.56s | Train loss: 2.8453 | Val loss: 3.2458 | Val accuracy: 20.29% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 193/193 [01:19<00:00,  2.43it/s, Training loss=2.7633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 took 86.82s | Train loss: 2.7633 | Val loss: 3.1829 | Val accuracy: 21.37% | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100:  15%|█▍        | 28/193 [00:12<01:13,  2.25it/s, Training loss=2.6252]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, train_dataloader, val_dataloader, optimiser, loss, device, epochs, early_stopper, device_path) \u001b[39m# train model\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/sc4001-neural-networks-and-deep-learning/practical/project/sc4001-project/models/common_utils.py:118\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, tl, vl, opt, loss, device, epochs, early_stopper, path)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Wrap the trainloader with tqdm for the progress bar\u001b[39;00m\n\u001b[1;32m    116\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(tl), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(tl), desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m train_loss \u001b[39m=\u001b[39m train_step(model, pbar, opt, device, loss)  \u001b[39m# Pass the tqdm-wrapped loader\u001b[39;00m\n\u001b[1;32m    119\u001b[0m val_loss, val_acc \u001b[39m=\u001b[39m val_step(model, vl, loss, device)\n\u001b[1;32m    121\u001b[0m train_loss_list\u001b[39m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m~/Desktop/sc4001-neural-networks-and-deep-learning/practical/project/sc4001-project/models/common_utils.py:68\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, trainloader, optimizer, device, lossfn)\u001b[0m\n\u001b[1;32m     65\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     66\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 68\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()  \u001b[39m# accumulate the loss\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     trainloader\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mTraining loss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(total_loss\u001b[39m/\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))})  \u001b[39m# Update the progress bar with the training loss\u001b[39;00m\n\u001b[1;32m     71\u001b[0m train_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(trainloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_list, val_loss_list, val_acc_list = train(model, train_dataloader, val_dataloader, optimiser, loss, device, epochs, early_stopper, device_path) # train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot train, test loss and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the graphs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_list, label=\"train loss\")\n",
    "plt.plot(val_loss_list, label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_acc_list, label=\"val accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
